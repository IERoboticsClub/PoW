{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceba59b3",
   "metadata": {},
   "source": [
    "# Importing Modules\n",
    "First we import all the various packages we will need to run this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22738af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import einops\n",
    "import tqdm\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from visualizer import Visualizer\n",
    "import cv2\n",
    "import time\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d810b1",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Then I defined a function that will record a video from the webcam so we can get a 'live' demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_video(duration=5, video_name=\"output.mp4\"):\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Define video codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(video_name, fourcc, 20.0, (640, 480))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # Write the frame to the output video\n",
    "            out.write(frame)\n",
    "            \n",
    "            # Display the frame in Jupyter Notebook\n",
    "            clear_output(wait=True)\n",
    "            display(cv2.imencode('.jpg', frame)[1].tostring())\n",
    "        \n",
    "        # Stop recording after the specified duration\n",
    "        if time.time() - start_time > duration:\n",
    "            break\n",
    "    \n",
    "    # Release the webcam and output video\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return video_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72968d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will load data from the file and return the buffer.\n",
    "def load_video(pth):\n",
    "    video = cv2.VideoCapture(pth)\n",
    "    video.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    video.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    video.set(cv2.CAP_PROP_FPS, 30)\n",
    "    buffer = []\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        buffer.append(frame)\n",
    "    return video, buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f272658",
   "metadata": {},
   "source": [
    "## Prepare Your Video\n",
    "An ideal length is at around 10 seconds, also depending on your computer performence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a90f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to record a 5-second video\n",
    "#vid = record_video(5, \"my_video.mp4\")\n",
    "vid = \"my_video.mp4\"\n",
    "# or optionally set the vid varaible to the path of where you video is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13bfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cotracker = torch.hub.load(\"facebookresearch/co-tracker\", \"cotracker_w8\")\n",
    "# load the model from the torch hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f59c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "video, buffer = load_video(vid)\n",
    "# load the video and video buffer using our helper method.\n",
    "video_tensor = torch.from_numpy(np.array(buffer)).permute(0, 3, 1, 2)[None].float()\n",
    "# we permutate the buffer to get our input data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2e1c2c",
   "metadata": {},
   "source": [
    "**Important** to note that the dimension in this explenation may differ from you video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbf697",
   "metadata": {},
   "source": [
    "The video_tensor object has a shape of EX: `torch.Size([1, 145, 3, 480, 640])`, which breaks down as follows:\n",
    "\n",
    "- The first dimension `[0]` is extra padding, often used for batch size, with a size of 1.\n",
    "- The second dimension `[1]` indicates there are 145 frames in the video.\n",
    "- The third dimension `[2]` represents the 3 color channels (likely RGB).\n",
    "- The fourth `[3]` and fifth `[4]` dimensions specify the video dimensions, which are 480 pixels in height and 640 pixels in width.\n",
    "\n",
    "So, for each of the 145 frames, you have a 3-channel color image with dimensions 480x640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cotracker = cotracker.cuda()\n",
    "    video_tensor = video_torch.cuda()\n",
    "# in case you are running a GPU this will load in order to optimize the runtime of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5634810",
   "metadata": {},
   "source": [
    "## Running the Model\n",
    "In the following code you can modify homnay points you want to track in your video, they will be displayed in a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c65b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta directly provides a method for use to use\n",
    "# it returns the tracks aswell as the visibility\n",
    "tracks, visibility = cotracker(\n",
    "    video_tensor,\n",
    "    grid_size=4, # here you modify the grid size\n",
    "    grid_query_frame=0, # here you modify from which frame the points should be tracked\n",
    "    backward_tracking=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fdfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks.shape)\n",
    "print(visibility.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77e908",
   "metadata": {},
   "source": [
    "The video_tensor object has a shape of `torch.Size([1, 145, 16, 2])`, indicating its dimensions. Here, 145 frames are present in the video. We've set a 4x4 grid to track specific points, totaling 16 points (4^2). For each of these 145 frames and 16 points, we store a 2D coordinate (x,y) to track the point's position, represented by the last dimension of the tensor. As for the visibility, since we just have it be 0 or 1, we need no extra dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4849630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"tracks.npy\", tracks.cpu().numpy()) # saving just to be sure\n",
    "np.save(\"visibility.npy\", visibility.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9add75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizer import Visualizer\n",
    "# another feature we get is the visualizer of the tracks\n",
    "# rather than having to dig through all of it\n",
    "# we can use their method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a07eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualizer(\n",
    "    save_dir=\"./\", # the directory where the file with the overlayed points will be\n",
    "    grayscale=False,\n",
    "    pad_value=100, # how much the output video gets visually padded\n",
    "    fps=30,\n",
    "    linewidth=2, # how wide the line will be in the video // only if we have them leave a trace\n",
    "    show_first_frame=5,\n",
    "    tracks_leave_trace=0 # the points will leave a trace\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename=\"my_video_tracked\" # the file output name\n",
    "file = vis.visualize(\n",
    "    video_tensor, # we pass the original video data\n",
    "    tracks=tracks, # the output of the model (tracks)\n",
    "    visibility=visibility, # output but visibility\n",
    "    filename=output_filename, # name of file name\n",
    "    query_frame=0, # the frame from which we start to display the tracks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f56b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video # just to show the video in the notebook\n",
    "Video(f\"./{output_filename}_pred_track.mp4\") # show the video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
